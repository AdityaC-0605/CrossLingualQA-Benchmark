# Model configurations for cross-lingual QA system

# Default model settings
model_name: "bert-base-multilingual-cased"
model_type: "mbert"
max_length: 384
max_target_length: 64
num_labels: 2  # start and end positions
hidden_dropout_prob: 0.1
attention_probs_dropout_prob: 0.1
num_beams: 4
early_stopping: true

# Model-specific training configurations
training:
  mbert:
    learning_rate: 3e-5
    weight_decay: 0.01
    warmup_steps: 1000
    max_grad_norm: 1.0
    adam_epsilon: 1e-8
    adam_beta1: 0.9
    adam_beta2: 0.999
    
  mt5:
    learning_rate: 1e-4
    weight_decay: 0.01
    warmup_steps: 1000
    max_grad_norm: 1.0
    adam_epsilon: 1e-8
    adam_beta1: 0.9
    adam_beta2: 0.999

# Device and memory configurations
device: "auto"  # Auto-detect best device (MPS > CUDA > CPU)
use_mps: true  # Apple Silicon GPU
use_cpu: false
mixed_precision: true
gradient_checkpointing: true
max_memory_gb: 16
